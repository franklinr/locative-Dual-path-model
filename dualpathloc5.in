# what-where model lens 2.3.1

addNet dualPath -i 30

## these are the input layers
set semSize 60
set lexSize 65
set eventsemSize 4
set whereSize 4

## hidden layers 
set hiddenSize 50
set compressSize 10
set ccompressSize 10
set bcomp -1
setObj numUpdates 1000

setObj learningRate 0.1
set strength 6 
set reducer 1
set treduce 0.5
set inittlink 0.5
set inittargtlink 0.5

set startlrate 0.15
set finallrate 0.01
set starttime 0
set timedecay 40000
set directWordHidden 0

setObj unitCellSize 9

seed 100

if {[file exists model.tcl]} {
  source model.tcl
  puts "ran model "
}
if {$bcomp > 0} {
   puts "set cmp "
   set compressSize $bcomp
   set ccompressSize $bcomp
}
set contextSize $hiddenSize

## create layers
addGroup cword $lexSize -BIASED OUT_WINNER
addGroup ccompress $ccompressSize -BIASED
addGroup cwhat $semSize OUTPUT TARGET_COPY -BIASED -WRITE_OUTPUTS
addGroup cwhere2 $whereSize ELMAN ELMAN_CLAMP ELMAN_CLAMP -BIASED  
addGroup cwhere $whereSize SOFT_MAX -BIASED 
addGroup eventsem $eventsemSize LINEAR -BIASED
addGroup context $contextSize ELMAN OUT_INTEGR -BIASED 
addGroup hidden $hiddenSize -BIASED
addGroup where $whereSize -BIASED
addGroup what $semSize -BIASED
addGroup compress $compressSize -BIASED 
addGroup targ $lexSize INPUT 
addGroup word $lexSize OUTPUT SOFT_MAX STANDARD_CRIT USE_OUTPUT_HIST USE_TARGET_HIST -BIASED 

## parameters for connections
## hystersis 1=copy  0=no change  
setObj context.dtScale 1
setObj cword.maxOutput 1

## connect layers
connectGroups cword cwhat -type cwordcwhat
connectGroups cwhat cwhere -type ww
connectGroups where what -type ww
connectGroups what word -type whatword
connectGroups hidden where -type hidwhere 
connectGroups context hidden -type conthid
connectGroups cwhere hidden -type prehid
connectGroups cwhere2 hidden -type prehid
connectGroups eventsem hidden -type esemhid
connectGroups hidden compress word -type hidword
if {$directWordHidden == 0} {
connectGroups cword ccompress hidden -type cwordhid
} else {
connectGroups cword hidden -type cwordhid
}

## connect bias
connectGroups bias eventsem -type bt
connectGroups bias what -type low
connectGroups bias cwhat -type low

## copy output of what units as training signal for cwhat units
copyConnect what cwhat outputs

## create elman unit connections and initial states
connectGroups targ cword -type cwordtype -proj ONE_TO_ONE
connectGroups word cword -type cwordtype -proj ONE_TO_ONE
elmanConnect cwhere cwhere2 -r 1 -init 0.0
elmanConnect cwhere2 cwhere2 -r 1 -init 0.0
elmanConnect hidden context -r 1 -init 0.5

## turn off learning for what-where cwhat-cwhere message weights
setLinkValue learningRate 0 -t ww
setLinkValues randMean  0 -t ww
setLinkValues randRange 0 -t ww

## turn off learning for event-semantic weights
setLinkValue learningRate 0 -t bt
setLinkValues randMean  0 -t bt
setLinkValues randRange 0 -t bt

## turn off learning for event-semantic weights
setLinkValue learningRate 0 -t cwordtype
setLinkValues randMean  1 -t cwordtype
setLinkValues randRange 0 -t cwordtype

## turn 
setLinkValue learningRate 0.1 -t cwordhid

## set bias of what units so that normal activation is low
setLinkValue learningRate 0 -t low
setLinkValues randMean  -3 -t low
setLinkValues randRange 0 -t low

## seed and randomize network
randWeights -t low
freezeWeight -t low

loadExamples trainl.ex
loadExamples testprodl.ex

setObj learningRate $startlrate
proc reduceLrate {} {
    global startlrate
    global starttime 
    global timedecay
    global finallrate
    set slope [expr ( $startlrate - $finallrate ) / $timedecay ]
    set updates [getObj totalUpdates]
    if {$updates > [expr $timedecay + $starttime ]} { 
    setObj learningRate $finallrate
    return;
    }
    if {$updates < $starttime} { return; }
    if {$updates % 500} return
    set lrate [expr $startlrate - $slope * ( $updates - $starttime ) ]
    setObj learningRate $lrate
    puts [getObj learningRate]
}
setObj preEpochProc reduceLrate

proc clear {} {
    randWeights -t ww
    randWeights -t bt
}
clear

proc link {input args} {
    global strength
    foreach j $args {
        setObj what.unit($j).incoming($input).weight $strength;
	setObj cwhere.unit($input).incoming($j).weight $strength;
    }
}

proc tlink {args} {
    global reducer
    global inittlink

    set tstrength $inittlink
    set randlevel [randInt 2]
    foreach j $args {
	if {$j < 0} {    	 
	    set tstrength [expr $tstrength * $reducer]
	} else {
	    setObj eventsem.unit($j).incoming(0).weight $tstrength;
 }	    }
}

proc saveTest {time {label ""} {numpats 0}} {
     set filename $time$label
     if {[file isdirectory results] == 0} { file mkdir results}
     if {[file isfile results/res$filename.out.gz] == 1} { set filename $filename.1 }

     openNetOutputFile results/res$filename.out
     test $numpats
     closeNetOutputFile
     exec gzip -f results/res$filename.out
     exec decode9.perl results/res$filename.out.gz | syncode.perl > sum$filename & 
}

proc useSaveTest {time set {numpats 0}} {
    useTestingSet $set
    exampleSetMode $set ORDERED
    saveTest $time $set $numpats
}

setObj batchSize 1
setObj numUpdates 2000
setObj reportInterval 1000
resetNet

proc trainSave {{lang ""} {max 10}} { 
 resetNet
  set numEpochs 4000
  loadExamples train$lang.ex
  loadExamples testprod$lang.ex

  for {set iepoch 0} {$iepoch < $max } {incr iepoch} {
      useTrainingSet train$lang
      exampleSetMode train$lang PERMUTED
      train $numEpochs

      set epo [getObj totalUpdates]
      saveWeights comp$epo.wt.gz

      ## only test 1000 train patterns      
      useSaveTest $epo train$lang 1000
      useSaveTest $epo testprod$lang

      set wtfile comp$epo.wt.gz
      loadWeights $wtfile

      puts [exec date]
  }
}

if {[file isdirectory results] == 0} { file mkdir results}

proc loadfile {command filename} {
   if {[file isfile $filename]} { $command $filename }
   if {[file isfile results/$filename]} { $command results/$filename }
}

proc testone {time set} {
    loadfile "loadWeight" comp$time.wt.gz
    useSaveTest $time $set
}

proc setlabels {layer args} {
  set c 0
  foreach n $args {
    setObj $layer.unit($c).name $n
    incr c 1
  }
}
